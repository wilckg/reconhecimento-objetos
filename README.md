# üéØ Detec√ß√£o de Objetos em Tempo Real com YOLOv8

Este reposit√≥rio cont√©m um script em Python para **detec√ß√£o de objetos** utilizando o modelo **YOLOv8**, da biblioteca [Ultralytics](https://docs.ultralytics.com/).  
Com ele, voc√™ pode rodar infer√™ncia em:

- üì∑ **Webcam**
- üñºÔ∏è **Imagens**
- üé• **V√≠deos**

√â um √≥timo ponto de partida para projetos de **Vis√£o Computacional**, **An√°lise Esportiva**, **Seguran√ßa**, ou simplesmente para experimentar redes neurais convolucionais aplicadas √† detec√ß√£o de objetos.

---

## üß† Vis√£o geral

O script `yolov8_detect.py`:

- Carrega um modelo YOLOv8 (por padr√£o, `yolov8n.pt`)
- Aceita diferentes fontes de entrada (`--source`)
- Exibe os resultados em tempo real com bounding boxes
- Opcionalmente salva as sa√≠das em `runs/detect/`
- Permite configurar confian√ßa, IoU e dispositivo (CPU / GPU)

---

## üì¶ Pr√©-requisitos

- Python **3.8+**
- `pip` atualizado
- (Opcional, mas recomendado) GPU NVIDIA com drivers + CUDA configurados

### üîß Criando ambiente virtual (opcional, mas recomendado)

```bash
python -m venv .venv
# Linux / WSL
source .venv/bin/activate
# Windows (PowerShell)
.\.venv\Scripts\Activate.ps1
```

### üì• Instalando depend√™ncias

```bash
pip install --upgrade pip
pip install ultralytics opencv-python
```

---

## üìÅ Estrutura do projeto (sugest√£o)

```bash
.
‚îú‚îÄ‚îÄ yolov8_detect.py    # Script principal de detec√ß√£o
‚îú‚îÄ‚îÄ README.md           # Este arquivo
‚îî‚îÄ‚îÄ media/              # (Opcional) Imagens e v√≠deos de teste
    ‚îú‚îÄ‚îÄ image.jpg
    ‚îî‚îÄ‚îÄ video.mp4
```

---

## üßæ Script principal (`yolov8_detect.py`)

> üîé *Esse √© o script esperado pelo README. Caso o seu esteja diferente, √© s√≥ ajustar aqui depois.*

```python
import argparse
from ultralytics import YOLO


def parse_args():
    parser = argparse.ArgumentParser(description="Detec√ß√£o de objetos com YOLOv8")
    parser.add_argument(
        "--source",
        type=str,
        default="0",
        help=(
            "Fonte de entrada:\n"
            " - caminho de imagem (ex: media/imagem.jpg)\n"
            " - caminho de v√≠deo (ex: media/video.mp4)\n"
            " - webcam (use '0' para webcam padr√£o)"
        ),
    )
    parser.add_argument(
        "--weights",
        type=str,
        default="yolov8n.pt",
        help="Caminho para o modelo YOLOv8 (.pt). Ex: yolov8n.pt, yolov8s.pt, modelo_treinado.pt",
    )
    parser.add_argument(
        "--conf",
        type=float,
        default=0.5,
        help="Confian√ßa m√≠nima para exibir detec√ß√µes (0.0 a 1.0)",
    )
    parser.add_argument(
        "--iou",
        type=float,
        default=0.45,
        help="IoU para NMS (Non-Max Suppression)",
    )
    parser.add_argument(
        "--device",
        type=str,
        default="",
        help="Dispositivo: '' (auto), 'cpu' ou '0', '1' para GPU espec√≠fica",
    )
    parser.add_argument(
        "--save",
        action="store_true",
        help="Se definido, salva o v√≠deo/imagens com detec√ß√µes em runs/detect/",
    )
    return parser.parse_args()


def main():
    args = parse_args()

    # Carrega modelo YOLOv8
    print(f"Carregando modelo: {args.weights}")
    model = YOLO(args.weights)

    # Prepara a fonte: se for "0", trata como webcam
    source = 0 if args.source == "0" else args.source

    print(f"Inferindo em: {source}")
    print("Pressione 'q' na janela de v√≠deo para encerrar (quando show=True).")

    results = model.predict(
        source=source,
        conf=args.conf,
        iou=args.iou,
        device=args.device if args.device else None,
        show=True,          # mostra janela com as detec√ß√µes
        save=args.save,     # salva resultados em runs/detect
        stream=False,       # True para stream (processar frame a frame)
        verbose=True,
    )

    # Opcional: imprimir resumo das detec√ß√µes
    for i, r in enumerate(results):
        if hasattr(r, "boxes") and r.boxes is not None:
            print(f"\n[Frame/Imagem {i}] {len(r.boxes)} objetos detectados:")
            for box in r.boxes:
                cls_id = int(box.cls[0])
                conf = float(box.conf[0])
                label = model.names[cls_id]
                print(f" - {label} ({conf:.2f})")

    print("\n‚úÖ Finalizado.")
    if args.save:
        print("Arquivos salvos em pasta runs/detect/")


if __name__ == "__main__":
    main()
```

---

## ‚ñ∂Ô∏è Como rodar

### 1Ô∏è‚É£ Webcam (padr√£o)

```bash
python yolov8_detect.py --source 0
```

### 2Ô∏è‚É£ Imagem

```bash
python yolov8_detect.py --source media/imagem.jpg
```

### 3Ô∏è‚É£ V√≠deo

```bash
python yolov8_detect.py --source media/video.mp4
```

### 4Ô∏è‚É£ Salvar os resultados (imagem/v√≠deo com boxes desenhados)

```bash
python yolov8_detect.py --source media/video.mp4 --save
```

Os arquivos processados ser√£o salvos em algo como:

```text
runs/detect/predict/
```

---

## ‚öôÔ∏è Par√¢metros √∫teis

| Par√¢metro   | Descri√ß√£o |
|------------|-----------|
| `--source` | Fonte de entrada: `0` (webcam), caminho de imagem, caminho de v√≠deo |
| `--weights`| Caminho do modelo `.pt` (ex: `yolov8n.pt`, `yolov8s.pt`, modelo treinado) |
| `--conf`   | Confian√ßa m√≠nima das detec√ß√µes (padr√£o: `0.5`) |
| `--iou`    | IoU para supress√£o de caixas (NMS) (padr√£o: `0.45`) |
| `--device` | Dispositivo: `cpu`, `0`, `1`... (GPU) |
| `--save`   | Se presente, salva os resultados em `runs/detect/` |

### Exemplos:

**For√ßar CPU:**

```bash
python yolov8_detect.py --source 0 --device cpu
```

**Usar modelo maior (mais preciso, por√©m mais pesado):**

```bash
python yolov8_detect.py --source 0 --weights yolov8s.pt
```

---

## üß™ Melhorando o projeto (id√©ias futuras)

- Treinar o YOLOv8 com um **dataset espec√≠fico** (por exemplo, jogadores de futebol)
- Integrar rastreamento com **DeepSORT** ou **ByteTrack**
- Exportar resultados (JSON/CSV) com as detec√ß√µes por frame
- Criar uma interface web ou dashboard (Streamlit, FastAPI, etc.)

---

## üìö Refer√™ncias

- [Ultralytics YOLOv8 ‚Äì Documenta√ß√£o Oficial](https://docs.ultralytics.com/)
- Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). *You Only Look Once: Unified, Real-Time Object Detection.*

---

## üë®‚Äçüíª Autor

**Wilck Gomes de Oliveira**  
Projeto acad√™mico e explorat√≥rio em Vis√£o Computacional e Deep Learning.

Se este reposit√≥rio foi √∫til, considere deixar uma ‚≠ê no GitHub! üôÇ
